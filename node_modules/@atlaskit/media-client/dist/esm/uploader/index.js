import _asyncToGenerator from "@babel/runtime/helpers/asyncToGenerator";
import _regeneratorRuntime from "@babel/runtime/regenerator";
import { chunkinator } from '@atlaskit/chunkinator';
import { from } from 'rxjs/observable/from';
import { concatMap } from 'rxjs/operators/concatMap';
import { createHasher } from '../utils/hashing/hasherCreator';
import { UploaderError } from './error';
import { CHUNK_SIZE, PROCESSING_BATCH_SIZE } from '../constants';
import { calculateChunkSize, fileSizeError } from './calculateChunkSize';

// TODO: Allow to pass multiple files

var _hashingFunction = /*#__PURE__*/function () {
  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(blob, hashAlgorithm) {
    var hasher;
    return _regeneratorRuntime.wrap(function _callee$(_context) {
      while (1) switch (_context.prev = _context.next) {
        case 0:
          _context.next = 2;
          return createHasher(hashAlgorithm);
        case 2:
          hasher = _context.sent;
          return _context.abrupt("return", hasher.hash(blob));
        case 4:
        case "end":
          return _context.stop();
      }
    }, _callee);
  }));
  return function hashingFunction(_x, _x2) {
    return _ref.apply(this, arguments);
  };
}();
var createUploadingFunction = function createUploadingFunction(store, deferredUploadId, collectionName, traceContext) {
  return /*#__PURE__*/function () {
    var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(chunk) {
      return _regeneratorRuntime.wrap(function _callee2$(_context2) {
        while (1) switch (_context2.prev = _context2.next) {
          case 0:
            _context2.t0 = store;
            _context2.t1 = chunk.hash;
            _context2.t2 = chunk.blob;
            _context2.next = 5;
            return deferredUploadId;
          case 5:
            _context2.t3 = _context2.sent;
            _context2.t4 = chunk.partNumber;
            _context2.t5 = collectionName;
            _context2.t6 = traceContext;
            _context2.next = 11;
            return _context2.t0.uploadChunk.call(_context2.t0, _context2.t1, _context2.t2, _context2.t3, _context2.t4, _context2.t5, _context2.t6);
          case 11:
            return _context2.abrupt("return", _context2.sent);
          case 12:
          case "end":
            return _context2.stop();
        }
      }, _callee2);
    }));
    return function (_x3) {
      return _ref2.apply(this, arguments);
    };
  }();
};
var createProcessingFunction = function createProcessingFunction(store, deferredUploadId, collection, traceContext) {
  var offset = 0;
  return /*#__PURE__*/function () {
    var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(chunks) {
      return _regeneratorRuntime.wrap(function _callee3$(_context3) {
        while (1) switch (_context3.prev = _context3.next) {
          case 0:
            _context3.t0 = store;
            _context3.next = 3;
            return deferredUploadId;
          case 3:
            _context3.t1 = _context3.sent;
            _context3.t2 = {
              chunks: hashedChunks(chunks),
              offset: offset
            };
            _context3.t3 = collection;
            _context3.t4 = traceContext;
            _context3.next = 9;
            return _context3.t0.appendChunksToUpload.call(_context3.t0, _context3.t1, _context3.t2, _context3.t3, _context3.t4);
          case 9:
            offset += chunks.length;
          case 10:
          case "end":
            return _context3.stop();
        }
      }, _callee3);
    }));
    return function (_x4) {
      return _ref3.apply(this, arguments);
    };
  }();
};
var createFileFromUpload = /*#__PURE__*/function () {
  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(file, store, uploadableFileUpfrontIds, uploadId, traceContext) {
    var collection, name, mimeType, id, occurrenceKey, body;
    return _regeneratorRuntime.wrap(function _callee4$(_context4) {
      while (1) switch (_context4.prev = _context4.next) {
        case 0:
          collection = file.collection, name = file.name, mimeType = file.mimeType;
          id = uploadableFileUpfrontIds.id, occurrenceKey = uploadableFileUpfrontIds.occurrenceKey;
          body = file.size ? {
            uploadId: uploadId,
            name: name,
            mimeType: mimeType,
            conditions: {
              size: file.size
            }
          } : {
            uploadId: uploadId,
            name: name,
            mimeType: mimeType
          };
          return _context4.abrupt("return", store.createFileFromUpload(body, {
            occurrenceKey: occurrenceKey,
            collection: collection,
            replaceFileId: id
          }, traceContext));
        case 4:
        case "end":
          return _context4.stop();
      }
    }, _callee4);
  }));
  return function createFileFromUpload(_x5, _x6, _x7, _x8, _x9) {
    return _ref4.apply(this, arguments);
  };
}();
export var uploadFile = function uploadFile(file, store, uploadableFileUpfrontIds, callbacks, traceContext) {
  var content = file.content,
    collection = file.collection;
  var deferredUploadId = uploadableFileUpfrontIds.deferredUploadId,
    id = uploadableFileUpfrontIds.id,
    occurrenceKey = uploadableFileUpfrontIds.occurrenceKey;
  var chunkSize = CHUNK_SIZE;
  try {
    if (content instanceof Blob) {
      chunkSize = calculateChunkSize(content.size);
    }
  } catch (err) {
    if (err instanceof Error && err.message === fileSizeError) {
      callbacks === null || callbacks === void 0 || callbacks.onUploadFinish(new UploaderError(err.message, {
        id: id,
        collectionName: collection,
        occurrenceKey: occurrenceKey
      }));
    }
    return {
      cancel: function cancel() {
        callbacks === null || callbacks === void 0 || callbacks.onUploadFinish('canceled');
      }
    };
  }
  var chunkinatorObservable = chunkinator(content, {
    hashingFunction: function hashingFunction(blob) {
      return _hashingFunction(blob, store.chunkHashAlgorithm);
    },
    hashingConcurrency: 5,
    chunkSize: chunkSize,
    uploadingConcurrency: 3,
    uploadingFunction: createUploadingFunction(store, deferredUploadId, collection, traceContext),
    processingBatchSize: PROCESSING_BATCH_SIZE,
    processingFunction: createProcessingFunction(store, deferredUploadId, collection, traceContext)
  }, {
    onProgress: function onProgress(progress) {
      if (callbacks) {
        callbacks.onProgress(progress);
      }
    }
  });
  var onUploadFinish = callbacks && callbacks.onUploadFinish || function () {};
  var subscription = from(deferredUploadId).pipe(concatMap(function (uploadId) {
    return chunkinatorObservable.pipe(concatMap(function () {
      return from(createFileFromUpload(file, store, uploadableFileUpfrontIds, uploadId, traceContext));
    }));
  })).subscribe({
    error: function error(err) {
      return onUploadFinish(err);
    },
    complete: function complete() {
      return onUploadFinish();
    }
  });
  return {
    cancel: function cancel() {
      subscription.unsubscribe();
      onUploadFinish('canceled');
    }
  };
};
var hashedChunks = function hashedChunks(chunks) {
  return chunks.map(function (chunk) {
    return chunk.hash;
  });
};