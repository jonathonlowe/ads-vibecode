import { chunkinator } from '@atlaskit/chunkinator';
import { createHasher } from './utils/hashing/hasherCreator';
const hashingFunction = async (blob) => {
    const hasher = await createHasher();
    return hasher.hash(blob);
};
const createProbingFunction = (store, collection) => async (chunks) => {
    const response = await store.probeChunks(hashedChunks(chunks), collection);
    const results = response.data.results;
    return Object.values(results).map((result) => result.exists);
};
const createUploadingFunction = (store, collection) => {
    return (chunk) => store.uploadChunk(chunk.hash, chunk.blob, collection);
};
const createProcessingFunction = (store, deferredUploadId, collection) => {
    let offset = 0;
    return async (chunks) => {
        await store.appendChunksToUpload(await deferredUploadId, {
            chunks: hashedChunks(chunks),
            offset,
        }, collection);
        offset += chunks.length;
    };
};
export const uploadFile = (file, store, uploadableFileUpfrontIds, callbacks) => {
    const { content, collection, name, mimeType } = file;
    const { id, occurrenceKey, deferredUploadId } = uploadableFileUpfrontIds;
    const { response, cancel } = chunkinator(content, {
        hashingFunction,
        hashingConcurrency: 5,
        probingBatchSize: 100,
        chunkSize: 4 * 1024 * 1024,
        uploadingConcurrency: 3,
        uploadingFunction: createUploadingFunction(store, collection),
        probingFunction: createProbingFunction(store, collection),
        processingBatchSize: 1000,
        processingFunction: createProcessingFunction(store, deferredUploadId, collection),
    }, {
        onProgress(progress) {
            if (callbacks) {
                callbacks.onProgress(progress);
            }
        },
    });
    const onUploadFinish = (callbacks && callbacks.onUploadFinish) || (() => { });
    Promise.all([deferredUploadId, response])
        .then(async ([uploadId]) => {
        await store.createFileFromUpload({ uploadId, name, mimeType }, {
            occurrenceKey,
            collection,
            replaceFileId: id,
        });
        onUploadFinish();
    })
        .catch(onUploadFinish);
    return { cancel };
};
const hashedChunks = (chunks) => chunks.map(chunk => chunk.hash);
//# sourceMappingURL=uploader.js.map